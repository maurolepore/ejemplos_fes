---
title: "R Notebook"
output: github_document
---



## 3 A Review of the Predictive Modeling Process

http://www.feat.engineering/review-predictive-modeling-process.html

## Covers how to

* measure model performance

* use data well (e.g. splitting and resampling)

* tune models

* compare model performance

## Uses data

* OkCupid Profile Data

* Ames housing price

## OkCupid Profile Data

<https://github.com/rudeboybert/JSE_OkCupid>

Goal: Predict whether a person's works in science, technology, engineering, and math (STEM).

* 50 000 profiles in San Francisco, USA

* Most data is categorical.
    * They converted it to dummy variables.

* STEM workers are infrequent (18.5%).
    * They "down-sampled" to ensure each class (e.g. STEM) has equal number of profiles.
    
## 3.2 Measuring Performance

<http://www.feat.engineering/measuring-performance.html>

## Metrics > regression > numeric

## Root Mean Squared Error (RMSE)

__Spoiler: Use it!__

* actual vs. predicted: average distance

* [original]

* Good -> RMSE ~ 0

## Coefficient of determination (R^2)

__Spoiler: Don't use it; prefer RMSE!__

* actual vs. predicted: (standard correlation)^2

## Coefficient of determination (R^2): Pro

For linear models:

* ~ How much variability can the model explain?

* [none] (proportion):
    * Good -> R^2 ~ 1
    * Bad -> R^2 ~ 0

## Coefficient of determination (R^2): Con

* can show very optimistic results when the y has large variance. 

* a handful of far predicted can artificially increase R^2.

* Measures correlation not accuracy. (Main problem.)

## R^2 Measures correlation not accuracy

> a model could produce predicted values that have a strong linear relationship with the actual values but the predicted values do not conform to the 45-degree line of agreement. 

## R^2 Measures correlation not accuracy

> E.g. when a model under-predicts at one extreme of the y and overpredicts at the other extreme of the y.

## R^2 problem: book example

(I don't get it)

<img src=http://i.imgur.com/lMFSHw2.png width=760>

## Concordance Correlation Coefficient (CCC)

* CCC penalizes R^2 for its bias (R^2 * bias)




# Appendix 

## R^2 problem: my example

```{r}
library(tidyverse)

actual <- tibble::tibble(x = 1:10, y = 1:10)

p <- ggplot(actual, aes(x, y)) + 
  geom_point(data = actual) +
  geom_abline()
p
```

```{r}
predicted <- tibble::tribble(
  ~x, ~y,
  # under-predict
  0,   2,  
  1,   3,
  2,   4,
  # over-predict
  8,   6,  
  9,   7,
  10,   8,
)

p + geom_point(data = predicted, color = "red")
```

```{r}
compare <- inner_join(
  actual, predicted, 
  by = "x", 
  suffix = c("_actual", "_predicted")
)

compare
```

```{r}
compare %>% 
  ggplot(aes(y_actual, y_predicted)) +
  xlim(0, 10) +
  ylim(0, 10) +
  geom_abline(slope = 1) +
  geom_point() +
  geom_smooth(method = "lm")
```

